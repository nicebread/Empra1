---
title: "Power Analysis: Introduction"
subtitle: "Slides: https://osf.io/t5rjf/"
author:
  - name: Felix Schönbrodt
    orcid: 0000-0002-8282-3910
    email: felix.schoenbrodt@psy.lmu.de
    affiliations: Ludwig-Maximilians-Universität München
date: 2024-04-19
footer: "Forschungsorientierte Praktikum I – Empirisches Praktikum, Ludwig-Maximilians-Universität München"
format: 
  FOMO-revealjs: 
    output-ext: slide.html
    transition: slide    
  html: default
revealjs-plugins:
  - attribution 
---
# Part I: General concepts of power analysis

# What is statistical power?

## A 2x2 classification matrix {visibility="hidden"}

|                                  |Reality: Effect present | Reality: No effect present | 
|----------------------------------|:-----------------------|:---------------------------|
| **Test indicates: Effect present**  | True Positive          | False Positive             |
| **Test indicates: No effect present**| False Negative         | True Negative              |

## A 2x2 classification matrix
![](img/matrix1.png)

##
![](img/meme1.png)

::: {.footer}
https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg
::: 

##
![](img/meme2.png)

::: {.footer}
https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg
::: 

##
![](img/matrix2.png)

## How to do a power analysis {visibility="hidden"}

::: {.r-stretch}

```{mermaid}

flowchart LR
    E["` **Effect Size** 
    (see Part II of the workshop)`"]
    D["` **Desired Power**
     usually 80%, 90% recommended for critical
studies (Bondavera, 2013)`"]
    L["` **Significance Level**
    0.05? 0.005 (Benjamin et al., 2018)? justify
your alpha (Lakens et al., 2018)? `"]
    S[Sample Size]
    L --> S
    D --> S
    E --> S


```

:::

::: {.smaller}
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E. J., Berk, R., ... & Cesarini, D. (2018). Redefine statistical
significance. Nature Human Behaviour, 2(1), 6. doi:10.1038/s41562-017-0189-z
Bondareva, D. (2013). Introduction to Power Analysis. Presentation for EPSE 482 Introduction to Statistics for Research in Education. Slides available at
slideshare.net/dbondareva/introduction-to-power-analysis
Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A., Argamon, S. E., ... & Buchanan, E. M. (2018). Justify your alpha. Nature Human Behaviour,
2, 168-171. doi: 10.1038/s41562-018-0311-x
:::

## How to do a power analysis 

::: {.r-stretch}

```{mermaid}

flowchart LR
    E[" Effect Size 
    (see Part II of the workshop)"]
    D[" Desired Power
     usually 80%, 90% recommended for critical
studies (Bondavera, 2013)"]
    L[" Significance Level
    0.05? 0.005 (Benjamin et al., 2018)? justify
your alpha (Lakens et al., 2018)? "]
    S[Sample Size]
    L --> S
    D --> S
    E --> S


```

:::

::: {.footer}
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E. J., Berk, R., ... & Cesarini, D. (2018). Redefine statistical
significance. Nature Human Behaviour, 2(1), 6. doi:10.1038/s41562-017-0189-z

Bondareva, D. (2013). Introduction to Power Analysis. Presentation for EPSE 482 Introduction to Statistics for Research in Education. Slides available at
slideshare.net/dbondareva/introduction-to-power-analysis

Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A., Argamon, S. E., ... & Buchanan, E. M. (2018). Justify your alpha. Nature Human Behaviour,
2, 168-171. doi: 10.1038/s41562-018-0311-x
:::

## Power is a frequentist property - beware of fallacies!

### Power is a pre-data measure (i.e., before data are collected) that averages over infinite hypothetical experiments

- Only one of these hypothetical experiments will actually be observed
- **Power is a property of the test procedure/ the design – not of a single study’s outcome!**

### Power is conditional on a hypothetical effect size – not conditional on the actual data obtained

- “Once the actual data are available, a power calculation is no longer conditioned on what is known, no longer corresponds to a valid inference, and may now be misleading.” ➙ for inference better use likelihood ratios or Bayes factors. Then pre-data power considerations are irrelevant.

::: {.footer}
Wagenmakers, E.-J., Verhagen, J., Ly, A., Bakker, M., Lee, M. D., Matzke, D., Rouder, J. N., et al. (2014). A power fallacy.Behavior Research Methods, 47, 913–917. doi:10.3758/s13428-014-0517-4
::: 


## Post hoc power considerations

- Using the observed effect size to calculate „post hoc
power“ is meaningless (it‘s just a transformation of the p-
value)
- It is however meaningful to estimate the power you have
achieved with your collected sample size and the a priori
assumed effect size („sensitivity power analysis“)

::: {.footer}
https://daniellakens.blogspot.com/2014/12/observed-power-and-what-to-do-if-your.html
Gelman, A. (2019). Don't calculate post-hoc power using observed estimate of effect size. Ann. Surg, 269, e9-e10
::: 

# Why power is important

## Exercise: <br> Given that p < .05: <br> What is the probability that a real effect exists in the population ➙ prob(H₁|D)

## {visibility="hidden"}

this part is not finished as I was unable to find a way to include the text outside the box while not putting another box around it -> see code below

::: {.r-stretch}

```{mermaid}
flowchart TB
    c1-->a2
    subgraph one
    a2
    end
    subgraph two
    b1-->b2
    end
    subgraph three
    c1-->c2
    end

```
:::

##
![](img/graph1.png)

::: {.footer}
Nuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. http://doi.org/10.1073/pnas.1313476110
::: 


##
![](img/graph2.png)

::: {.footer}
Nuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. http://doi.org/10.1073/pnas.1313476110
::: 


##
![](img/graph3.png)


::: {.footer}
Nuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. http://doi.org/10.1073/pnas.1313476110
::: 


##
![](img/article1.png)

Assumed that our tested hypothesis are true in 30% of all cases (which is a not too risky research scenario):

- **A typical neuroscience study must "fail" (p > α) in 90% of all cases**

- **In the most likely outcome of p > .05, we have no idea whether a) the effect does not exist, or b) we simply missed the effect. Virtually no knowledge has been gained.**

::: {.footer}
Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: why small sample size  undermines the reliability of neuroscience. Nat Rev Neurosci, 14(5), 365–376. doi:10.1038/nrn3475
::: 

##

![](img/graph4.jpg)

::: {.footer}
Smaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. arXiv:1605.09511 [physics, stat]. Retrieved from http://arxiv.org/abs/1605.09511
::: 



##

![](img/text1.png)

::: {.footer}
Schönbrodt, F. D. & Wagenmakers, E.-J. (2016). Bayes Factor Design Analysis: Planning for Compelling Evidence. http://dx.doi.org/10.2139/ssrn.2722435 
::: 

## A power analysis helps you to find a balance between...

![](img/balance.png)

::: {.footer}
Pictures from nature.com/articles/srep43627, pngimg.com/download/23544, whyopenresearch.org/funding
::: 

# Researcher‘s intuitions about power

## Researcher’s intuitions about power

![](img/intuition.png)

::: {.footer}
Bakker, M., Hartgerink, C. H. J., Wicherts, J. M., & van der Maas, H. L. J. (2016). Researchers’ Intuitions About Power in Psychological Research. Psychological Science, 27(8), 1069–1077. http://doi.org/10.1177/0956797616647519
::: 

## Calibrate your power feeling

![](img/table1.png)

## Calibrate your power feeling
![](img/table2.png)

# Clever designs go a long way

## The power of within-SS designs

![](img/graph5.jpg){fig-align="left"}

- Why? Each person is his/her own control group
- For example, for the paired t-test:

::: {.smaller}
- By computing the within-person difference scores, all between-person variance (which contributes to error variance), gets removed
- Less error variance = less noise = (relatively) more signal = larger effect size
::: 

## Increase power with reliable measures

![](img/table3.png)

- Cohen’s d = 0.4
- N = 30
- pre-post-test

::: {.footer}
Heo, M., Kim, N., & Faith, M. S. (2015). Statistical power as a function of Cronbach alpha of instrument questionnaire items. 
BMC Medical Research Methodology, 15. doi:10.1186/s12874-015-0070-6
::: 


## Specific predictions? <br> Use one-tailed tests!

- One-tailed tests have a higher power than two-tailed tests
- Particularly recommended in combination with a preregistration
- Most power analysis approaches (G*Power, R packages) allow you to chose between one- and two-tailed tests


# Any questions so far?


# Part II: <br> Effect sizes / smallest effects of interests

# Common effect size metrics

##  Common effect sizes

![](img/table4.png)

##  Effect size transformations
![](img/table5.png)

##  Effect size transformations
![](img/table6.png)

::: {.footer}
Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Effect sizes based on correlations. In Introduction to Meta-Analysis, p. 45-49.
Brysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference
Tables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: https://doi.org/10.5334/joc.72
Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and
ANOVAs. Frontiers in Psychology, 4. https://doi.org/10.3389/fpsyg.2013.00863
::: 

## Converting among effect sizes
![](img/conversion1.png)

::: {.footer}
Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Converting among effect sizes. In Introduction to Meta-Analysis, p. 45-49.
Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and
ANOVAs. Frontiers in Psychology, 4. https://doi.org/10.3389/fpsyg.2013.00863
::: 

## Converting among effect sizes
![](img/conversion2.png)

::: {.footer}
https://www.ibm.com/support/pages/effect-size-relationship-between-partial-eta-squared-cohens-f-and-cohens-d
Brysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference
Tables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: https://doi.org/10.5334/joc.72
::: 

## Converting among effect sizes
![](img/conversion3.png)

::: {.footer}
Brysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference
Tables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: https://doi.org/10.5334/joc.72
::: 

## Converting among effect sizes
![](img/conversion4.png)




# Getting a feeling about effect sizes

## How do these effect sizes look like?
![](img/graph6.png){fig-align="center"}

::: {.footer}
https://rpsychologist.com/d3/cohend/
::: 

## How do these effect sizes look like?
![](img/graph7.png){fig-align="center"}

::: {.footer}
https://rpsychologist.com/d3/cohend/
::: 

## How do these effect sizes look like?
![](img/graph8.png){fig-align="center"}

::: {.footer}
https://rpsychologist.com/d3/cohend/
::: 


## Guess the correlation
![](img/corrguess1.png){fig-align="center"}

::: {.footer}
http://guessthecorrelation.com/
::: 

## Guess the correlation
![](img/corrguess2.png){fig-align="center"}

::: {.footer}
http://guessthecorrelation.com/
::: 


::: footer
Siehe [https://www.fak11.lmu.de/dep_psychologie/studium/lehrelounge/benotung-schriftl-arbeiten/index.html](https://www.fak11.lmu.de/dep_psychologie/studium/lehrelounge/benotung-schriftl-arbeiten/index.html)
:::


<!--Footer insert below -->
```{r child="../../common/lastslide.qmd"}
```
