{
  "hash": "806d6d5cd466eccea65226f4a0227e7e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Power Analysis: Introduction\"\nsubtitle: \"Slides: https://osf.io/t5rjf/\"\nauthor:\n  - name: Felix Schönbrodt\n    orcid: 0000-0002-8282-3910\n    email: felix.schoenbrodt@psy.lmu.de\n    affiliations: Ludwig-Maximilians-Universität München\ndate: 2024-04-19\nfooter: \"Forschungsorientierte Praktikum I – Empirisches Praktikum, Ludwig-Maximilians-Universität München\"\nformat: \n  nicetheme-revealjs: \n    output-ext: slide.html\n    transition: slide    \n  html: default\nrevealjs-plugins:\n  - attribution \n---\n\n# Part I: General concepts of power analysis\n\n# What is statistical power?\n\n## A 2x2 classification matrix {visibility=\"hidden\"}\n\n|                                  |Reality: Effect present | Reality: No effect present | \n|----------------------------------|:-----------------------|:---------------------------|\n| **Test indicates: Effect present**  | True Positive          | False Positive             |\n| **Test indicates: No effect present**| False Negative         | True Negative              |\n\n## A 2x2 classification matrix\n![](img/matrix1.png)\n\n##\n![](img/meme1.png)\n\n::: {.footer}\n[https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg](https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg)\n::: \n\n##\n![](img/meme2.png)\n\n::: {.footer}\n[https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg](https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg)\n::: \n\n##\n![](img/matrix2.png)\n\n\n\n## How to do a power analysis \n\n::: {.r-stretch}\n\n\n```{mermaid}\n\nflowchart LR\n    E[\" Effect Size \n    (see Part II of the workshop)\"]\n    D[\" Desired Power\n     usually 80%, 90% recommended for critical\nstudies (Bondavera, 2013)\"]\n    L[\" Significance Level\n    0.05? 0.005 (Benjamin et al., 2018)? justify\nyour alpha (Lakens et al., 2018)? \"]\n    S[Sample Size]\n    L --> S\n    D --> S\n    E --> S\n\n```\n\n\n:::\n\n::: {.footer}\n::: {.smaller}\nBenjamin et al. (2018). Redefine statistical significance. doi:[10.1038/s41562-017-0189-z]([10.1038/s41562-017-0189-z]()); Lakens et al. (2018). Justify your alpha. doi:[10.1038/s41562-018-0311-x](https://pure.tue.nl/ws/portalfiles/portal/119109470/Lakens_et_al._2018_Justify_your_alpha.pdf)\n:::\n:::\n\n## Power is a frequentist property - beware of fallacies!\n\n### Power is a pre-data measure (i.e., before data are collected) that averages over infinite hypothetical experiments\n\n- Only one of these hypothetical experiments will actually be observed\n- **Power is a property of the test procedure/ the design – not of a single study’s outcome!**\n\n### Power is conditional on a hypothetical effect size – not conditional on the actual data obtained\n\n- “Once the actual data are available, a power calculation is no longer conditioned on what is known, no longer corresponds to a valid inference, and may now be misleading.” ➙ for inference better use likelihood ratios or Bayes factors. Then pre-data power considerations are irrelevant.\n\n::: {.footer}\nWagenmakers, E.-J., Verhagen, J., Ly, A., Bakker, M., Lee, M. D., Matzke, D., Rouder, J. N., et al. (2014). A power fallacy.Behavior Research Methods, 47, 913–917. doi:10.3758/s13428-014-0517-4\n::: \n\n\n## Post hoc power considerations\n\n- Using the observed effect size to calculate „post hoc\npower“ is meaningless (it‘s just a transformation of the p-\nvalue)\n- It is however meaningful to estimate the power you have\nachieved with your collected sample size and the a priori\nassumed effect size („sensitivity power analysis“)\n\n::: {.footer}\n[https://daniellakens.blogspot.com/2014/12/observed-power-and-what-to-do-if-your.html](https://daniellakens.blogspot.com/2014/12/observed-power-and-what-to-do-if-your.html)\nGelman, A. (2019). Don't calculate post-hoc power using observed estimate of effect size. Ann. Surg, 269, e9-e10\n::: \n\n# Why power is important\n\n## Exercise: <br> Given that p < .05: <br> What is the probability that a real effect exists in the population ➙ prob(H₁|D)\n\n## {visibility=\"hidden\"}\n\nthis part is not finished as I was unable to find a way to include the text outside the box while not putting another box around it -> see code below\n\n::: {.r-stretch}\n\n\n```{mermaid}\nflowchart TB\n    c1-->a2\n    subgraph one\n    a2\n    end\n    subgraph two\n    b1-->b2\n    end\n    subgraph three\n    c1-->c2\n    end\n\n```\n\n:::\n\n##\n![](img/graph1.png)\n\n::: {.footer}\nNuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. [http://doi.org/10.1073/pnas.1313476110](http://doi.org/10.1073/pnas.1313476110)\n::: \n\n\n##\n![](img/graph2.png)\n\n::: {.footer}\nNuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. [http://doi.org/10.1073/pnas.1313476110](http://doi.org/10.1073/pnas.1313476110)\n::: \n\n\n##\n![](img/graph3.png)\n\n\n::: {.footer}\nNuzzo, R. (2014). Statistical errors. Nature. Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open Science, 1(3), 140216–140216. [http://doi.org/10.1073/pnas.1313476110](http://doi.org/10.1073/pnas.1313476110)\n::: \n\n\n##\n![](img/article1.png)\n\nAssumed that our tested hypothesis are true in 30% of all cases (which is a not too risky research scenario):\n\n- **A typical neuroscience study must \"fail\" (p > α) in 90% of all cases**\n\n- **In the most likely outcome of p > .05, we have no idea whether a) the effect does not exist, or b) we simply missed the effect. Virtually no knowledge has been gained.**\n\n::: {.footer}\nButton, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: why small sample size  undermines the reliability of neuroscience. Nat Rev Neurosci, 14(5), 365–376. doi:10.1038/nrn3475\n::: \n\n## {visibility=\"hidden\"}\n\n![](img/graph4.jpg) \n\n::: {.footer}\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. arXiv:1605.09511 [physics, stat]. Retrieved from [http://arxiv.org/abs/1605.09511](http://arxiv.org/abs/1605.09511)\n::: \n\n\n##\n> When a study is underpowered it most likely provides only weak inference. Even before a single participant is assessed, it is highly unlikely that an underpowered study provides an informative result.\n>\n> Consequently, research unlikely to produce diagnostic outcomes is inefficient and can even be considered unethical. Why sacrifice people's time, animals' lives, and societies' resources on an experiment that is highly unlikely to be informative?\n\n::: {.footer}\nSchönbrodt, F. D. & Wagenmakers, E.-J. (2018). [Bayes Factor Design Analysis: Planning for compelling evidence](https://osf.io/d4dcu/). Psychonomic Bulletin & Review, 25, 128-142. doi:10.3758/s13423-017-1230-y\n::: \n\n## A power analysis helps you to find a balance between...\n\n![](img/balance.png)\n\n::: {.footer}\nPictures from [nature.com/articles/srep43627](nature.com/articles/srep43627), [pngimg.com/download/23544](pngimg.com/download/23544), [whyopenresearch.org/funding](whyopenresearch.org/funding)\n::: \n\n# Researcher‘s intuitions about power\n\n## Researcher’s intuitions about power\n\n![](img/intuition.png)\n\n::: {.footer}\nBakker, M., Hartgerink, C. H. J., Wicherts, J. M., & van der Maas, H. L. J. (2016). Researchers’ Intuitions About Power in Psychological Research. Psychological Science, 27(8), 1069–1077. [http://doi.org/10.1177/0956797616647519](http://doi.org/10.1177/0956797616647519)\n::: \n\n## Calibrate your power feeling\n\n![](img/table1.png)\n\n## Calibrate your power feeling\n![](img/table2.png)\n\n# Clever designs go a long way\n\n## The power of within-SS designs\n\n:::: {.columns}\n::: {.column width=\"40%\"}\n![](img/graph5.jpg){fig-align=\"left\"}\n:::\n\n:::{.column width=\"60%\"}\n\n- Why? Each person is his/her own control group\n- For example, for the paired t-test:\n\n  - By computing the within-person difference scores, all between-person variance (which contributes to error variance), gets removed\n  - Less error variance &rarr;  less noise &rarr; (relatively) more signal \n&rarr; larger effect size\n\n:::\n\n::::\n\n\n## Increase power with reliable measures\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n![](img/table3.png)\n:::\n\n:::{.column width=\"40%\"}\n- Cohen’s d = 0.4\n- N = 30\n- pre-post-test\n:::\n::::\n\n::: {.footer}\nHeo, M., Kim, N., & Faith, M. S. (2015). Statistical power as a function of Cronbach alpha of instrument questionnaire items. \nBMC Medical Research Methodology, 15. doi:10.1186/s12874-015-0070-6\n::: \n\n\n\n## Specific predictions? <br> Use one-tailed tests!\n\n- One-tailed tests have a higher power than two-tailed tests\n- Particularly recommended in combination with a preregistration\n- Most power analysis approaches (G*Power, R packages) allow you to chose between one- and two-tailed tests\n\n\n# Any questions so far?\n\n\n# Part II: <br> Effect sizes / smallest effects of interests\n\n# Common effect size metrics\n\n##  Common effect sizes\n\n![](img/table4.png)\n\n##  Effect size transformations\n![](img/table5.png)\n\n##  Effect size transformations\n![](img/table6.png)\n\n::: {.attribution}\nBorenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Effect sizes based on correlations. In Introduction to Meta-Analysis, p. 45-49.\nBrysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference\nTables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: [https://doi.org/10.5334/joc.72](https://doi.org/10.5334/joc.72)\nLakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and\nANOVAs. Frontiers in Psychology, 4. [https://doi.org/10.3389/fpsyg.2013.00863](https://doi.org/10.3389/fpsyg.2013.00863)\n::: \n\n## Converting among effect sizes\n![](img/conversion1.png)\n\n::: {.footer}\nBorenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Converting among effect sizes. In Introduction to Meta-Analysis, p. 45-49.\nLakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and\nANOVAs. Frontiers in Psychology, 4. [https://doi.org/10.3389/fpsyg.2013.00863](https://doi.org/10.3389/fpsyg.2013.00863)\n::: \n\n## Converting among effect sizes\n![](img/conversion2.png)\n\n::: {.footer}\n[https://www.ibm.com/support/pages/effect-size-relationship-between-partial-eta-squared-cohens-f-and-cohens-d](https://www.ibm.com/support/pages/effect-size-relationship-between-partial-eta-squared-cohens-f-and-cohens-d)\nBrysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference\nTables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: [https://doi.org/10.5334/joc.72](https://doi.org/10.5334/joc.72)\n::: \n\n## Converting among effect sizes\n![](img/conversion3.png)\n\n::: {.footer}\nBrysbaert, M. (2019) How Many Participants Do We Have to Include in Properly Powered Experiments? A Tutorial of Power Analysis with Reference\nTables. Journal of Cognition, 2(1): 16, pp. 1–38. DOI: [https://doi.org/10.5334/joc.72](https://doi.org/10.5334/joc.72)\n::: \n\n## Converting among effect sizes\n![](img/conversion4.png)\n\n\n\n\n# Getting a feeling about effect sizes\n\n## How do these effect sizes look like?\n![](img/graph6.png){fig-align=\"center\"}\n\n::: {.footer}\n[https://rpsychologist.com/d3/cohend/](https://rpsychologist.com/d3/cohend/)\n::: \n\n## How do these effect sizes look like?\n![](img/graph7.png){fig-align=\"center\"}\n\n::: {.footer}\n[https://rpsychologist.com/d3/cohend/](https://rpsychologist.com/d3/cohend/)\n::: \n\n## How do these effect sizes look like?\n![](img/graph8.png){fig-align=\"center\"}\n\n::: {.footer}\n[https://rpsychologist.com/d3/cohend/](https://rpsychologist.com/d3/cohend/)\n::: \n\n\n## Guess the correlation\n![](img/corrguess1.png){fig-align=\"center\"}\n\n::: {.footer}\n[http://guessthecorrelation.com/](http://guessthecorrelation.com/)\n::: \n\n## Guess the correlation\n![](img/corrguess2.png){fig-align=\"center\"}\n\n::: {.footer}\n[http://guessthecorrelation.com/](http://guessthecorrelation.com/)\n::: \n\n## Understanding effect sizes\n\n![](img/effectsize.png){fig-align=\"left\"}\n\nMore understandable metrics: „Common Language Effect Size“, CLES:\n\n- …the probability that a randomly sampled person from one group will have a higher observed measurement than a randomly sampled person from the other group (for between designs)\n- …or (for within-designs) the probability that an individual has a higher value on one measurement than the other.\n\n::: {.footer}\nMcGraw, K. O., & Wong, S. P. (1992). A common language effect size statistic. Psychological Bulletin, 111(2), 361–365. [https://doi.org/10.1037/0033-2909.111.2.361](https://doi.org/10.1037/0033-2909.111.2.361)\nLakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4. [https://doi.org/10.3389/fpsyg.2013.00863](https://doi.org/10.3389/fpsyg.2013.00863)\n::: \n\n## Understanding effect sizes\n\nExample: *d* = 0.4, *n* = 55 in each group\n\n- Repeated-measures factor: 61% of the participants change into the expected direction\n- Between-groups factor: 61% chance of finding the expected ordering if you test a random participant from each sample\n\n# Typical effect sizes\n\n## Cohen‘s conventions\n![](img/cohen.png){fig-align=\"left\"}\n\nIs this reasonable?\n\n## Typical reported effect sizes I\n### Richard, Bond, & Stokes-Zoota (2003):\n\n- Meta-meta-analysis; > 25.000 studies, > 8.000.000\nparticipants\n- mean effect *r* = .21 (across literature *SD* = .15); median = .18\n\n![](img/reportedeffectsize.png){fig-align=\"center\" height=420px}\n\n::: {.footer}\nRichard, F. D., Bond, C. F. J., & Stokes-Zoota, J. J. (2003). One Hundred Years of Social Psychology Quantitatively Described. Review of General Psychology, 7(4), 331–363. doi:10.1037/1089-2680.7.4.331\n:::\n\n## Typical reported effect sizes I\n### Richard, Bond, & Stokes-Zoota (2003):\n![](img/table7.png){fig-align=\"center\" height=450px}\n\n\n## Typical reported effect sizes II\n### Bosco et al. (2015):\n\n- 147,328 correlations from Journal of Applied Psychology and Personnel Psychology\n- median effect: *r* = .16,  mean effect *r* = .22 (SD = .20)\n\n![](img/graph9.jpg){fig-align=\"center\"}\n\n\n\n::: {.footer}\nBosco, F. A., Aguinis, H., Singh, K., Field, J. G., & Pierce, C. A. (2015). Correlational effect size benchmarks. Journal of Applied Psychology, 100(2), 431–449. [http://doi.org/10.1037/a0038047](http://doi.org/10.1037/a0038047)\n:::\n\n## Typical reported effect sizes III\n### Hill et al. (2008):\n\n- How does the effect of an intervention compare to a typical year of growth in\nschool?\n\n![](img/hedgesg.png){fig-align=\"center\"}\n\n::: {.footer}\nHill, C. J., Bloom, H. S., Black, A. R., & Lipsey, M. W. (2008). Empirical Benchmarks for Interpreting Effect Sizes in Research. Child Development Perspectives, 2, 172–177. doi:10.1111/j.1750-8606.2008.00061.x\n:::\n\n## Typical reported effect sizes IV\n### Funder & Ozer (2019):\n\n![](img/graph10.jpg){fig-align=\"center\"}\n\n::: {.footer}\nFunder, D. C., & Ozer, D. J. (2019). Evaluating Effect Size in Psychological Research: Sense and Nonsense. Advances in Methods and Practices in Psychological Science, 2, 156–168. doi:10.1177/2515245919847202\n:::\n\n## Typical reported effect sizes V\n### Aguinis, Beaty, Boik, & Pierce (2005):\n- Effect size of interaction from dichotomous moderator and continuous predictor\n![](img/table8.png){fig-align=\"center\"}\n\n::: {.footer}\nAguinis, H., Beaty, J. C., Boik, R. J., & Pierce, C. A. (2005). Effect size and power in assessing moderating effects of categorical variables using multiple regression: a 30-year review. Journal of applied psychology, 90(1), 94.\n:::\n\n## Other benchmarks I\n::: {.callout-caution collapse=\"true\"}\n# Average placebo effect?\n*d* = 0.24 [0.17; 0.31]!\n:::\n\n::: {.footer}\nHróbjartsson, A., & Gøtzsche, P. C. (2004). Is the placebo powerless? Update of a systematic review with 52 new randomized trials comparing placebo with no treatment. Journal of internal medicine, 256(2), 91-100.\n:::\n\n## Other benchmarks II (ES: *d*)\n\n![](img/graph11.png){fig-align=\"center\"}\n\n::: {.footer}\nLuhmann, M., Hofmann, W., Eid, M., & Lucas, R. E. (2012). Subjective well-being and adaptation to life events: a meta-analysis. Journal of Personality and\nSocial Psychology, 102(3), 592–615. [http://doi.org/10.1037/a0025948](http://doi.org/10.1037/a0025948)\n:::\n\n# The trustworthiness of effect sizes in the literature\n\n##\n\n![](img/sampletopower.png){fig-align=\"center\"}\n\n::: {.footer}\nBakker, M., van Dijk, A., & Wicherts, J. M. (2012). The Rules of the Game Called Psychological Science. Perspectives on Psychological Science, 7(6), 543–554.\n:::\n\n##\n\n![](img/graph12.png){fig-align=\"center\"}\n\n::: {.footer}\nFanelli, D. (2011). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891–904. doi:10.1007/s11192-011-0494-7\n:::\n\n\n## Can we base our power analyses on published effect sizes?\n**No.**\n\n- See RP:P: 83% of all effect sizes are smaller than the original: <br> Mean original: r = .40 ➙ Mean replication: r = .20\n- See also Franco et al. (2015): <br> Reported ES 2x larger than unreported ES\n\n## Can we base our power analyses on published effect sizes?\n• See Schäfer & Schwarz (2019), ES: r:\n\n![](img/powerfromeffectsize.png){fig-align=\"center\"}\n\n::: {.footer}\nSchäfer, T., & Schwarz, M. A. (2019). The meaningfulness of effect sizes in psychological research: Differences between sub-disciplines and the impact of potential biases.Frontiers in Psychology,10, 813.\n:::\n\n## Can we base our power analyses on published effect sizes?\n\n- Suggestion 1: Divide reported effect by 2, compute power analysis.\n- Suggestion 2: Safeguard power (Perugini, 2014): Incorporate uncertainty in original study’s ES estimate. Aim lower end of 60%-CI.\n\n## Safeguard power \n(Perugini et al., 2014)\n\n- Incorporate uncertainty in original study’s ES estimate\n- Aim for lower end of 60%-CI\n- Example: \n  - Original study finds d = 0.5 (n = 30 in each group)\n  - 60% CI = [0.28; 0.72]\n  - Naive 80% power analysis: n = 64\n  - Safeguard 80% power analysis: n = 202\n- Rewards precise estimates in original study\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MBESS)\nci.smd(smd=0.5, n.1=30, n.2=30, conf.level=0.60)\n```\n:::\n\n\n## Write-Up\n![](img/writeup1.png){fig-align=\"center\"}\n\n::: {.footer}\n[https://twitter.com/GuyProchilo/status/1292780240977223681](https://twitter.com/GuyProchilo/status/1292780240977223681)\n:::\n\n## Write-Up\n![](img/writeup2.png){fig-align=\"center\"}\n\n::: {.footer}\nLakens (2021). Sample Size Justification. [https://psyarxiv.com/9d3yf/]( https://psyarxiv.com/9d3yf/)\n:::\n\n::: {.footer}\nPerugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard Power as a Protection Against Imprecise Power Estimates. Perspectives on Psychological Science, 9(3), 319–332. [http://doi.org/10.1177/1745691614528519](http://doi.org/10.1177/1745691614528519)\n:::\n\n\n::: footer\nSiehe [https://www.fak11.lmu.de/dep_psychologie/studium/lehrelounge/benotung-schriftl-arbeiten/index.html](https://www.fak11.lmu.de/dep_psychologie/studium/lehrelounge/benotung-schriftl-arbeiten/index.html)\n:::\n\n\n<!--Footer insert below -->\n\n\n# End\n\n## Contact\n\n<script src=\"https://kit.fontawesome.com/9fb269b0d2.js\" crossorigin=\"anonymous\"></script>\n\n<ul class=\"fa-ul\" style=\"color:black; list-style:none;\">\n\n<li><i class=\"fa-brands fa-li fa-mastodon\"></i> <a href=\"https://scicomm.xyz/@nicebread\" target=\"_blank\" style=\"color:black; border-bottom:none;\">@nicebread@scicomm.xyz</a></li>\n\n<li><i class=\"fa-li fa fa-envelope-o\"></i> <a style=\"unicode-bidi:bidi-override; direction: rtl; color:black\" href=\"javascript:window.location.href = 'mailto:' + ['felix.schoenbrodt','psy.lmu.de'].join('@')\">ed.uml.ysp@tdorbneohcs.xilef</a></li>\n\n<li><i class=\"fa-li fa-solid fa-globe\"></i> <a href=\"https://www.nicebread.de\" target=\"_blank\" style=\"color:black; border-bottom:none;\">https://www.nicebread.de</a></li>\n\n\n<li><i class=\"fa-li fa fa-github\" aria-hidden=\"true\"></i> <a href=\"https://github.com/nicebread\" target=\"_blank\" style=\"color:black; border-bottom:none;\">https://github.com/nicebread</a></li>\n</ul>\n\n<small style=\"text-align:left;\">\n[![CC-BY-SA 4.0][cc-by-sa-image]][cc-by-sa]\n\n[cc-by-sa]: http://creativecommons.org/licenses/by-sa/4.0/\n[cc-by-sa-image]: https://licensebuttons.net/l/by-sa/4.0/88x31.png\n[cc-by-sa-shield]: https://img.shields.io/badge/License-CC%20BY%20SA4.0-lightgrey.svg\n</small>\n",
    "supporting": [
      "Power-Analysis-general-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}